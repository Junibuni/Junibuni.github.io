---
title: DCGAN 이론
date: 2023-12-06 23:56:00 +0800
categories: [AI, GAN]
tags: [dcgan, deep learning, cnn, image generation, neural network, ml, ai, gan, image synthesis, computer vision, dnn, image processing, python, pytorch]
use_math: true
---
# 생성모델
컴퓨터는 어떻게 존재하지 않는 그럴싸한 이미지를 만들어 낼 수 있을까?

## 이미지 데이터
이미지 데이터는 다차원 특징 공간의 한 점으로 표현 된다. 사람들의 키 분포도가 아래와 같이 주어졌을 때, 특정 사람의 키는 1차원 공간의 점 (키)로 표현 될 수 있다. 당연한 얘기지만, 이미지 데이터와 같이 다차원 공간에 존재하는 데이터도 마찬가지라는 얘기다. 따라서 이미지의 분포를 근사하는 모델을 생성한다면, 그럴싸한 데이터를 생성할 수 있다는 얘기이다!
<img src="{{page.img_pth}}height_distribution.png">

정리하자면, 생성모델은 다음과 같이 설명할 수 있다.
- 결합확률분포 (joint probability distribution) 의 통계모델
- 새로운 인스턴스 (new data instances)를 생성하는 아키텍쳐

## 생성모델의 목표


이미지 생성모델의 목표라고 하면, 이미지 데이터의 분포를 근사하는 모델, G (Generator) 를 만드는 것이 생성모델의 목표이다. 이때, 모델 G 가 원래 이미지의 분포를 잘 모델링 할 수 있다면 잘 동작한다고 볼 수 있다.

# Generative Adversarial Network (GAN)
GAN은 이름에서 볼 수 있듯이, 적대적인(Adversarial) 네트워크이다. 이게 무슨 뜻인가 하면, 두개의 네트워크를 함께 학습한다는 뜻이다. 두가지 모델은 생성자(Generator)와 판별자(Discriminator)로 이루어져 있고, inference 과정에서는 생성자 모델만 쓰여 새로운 이미지를 생성하게 된다. 이 두가지 모델을 함께 학습시키면서 생성모델을 학습할 수 있게 된다. 생성자는 다음과 같은 목적함수(objective funtion)을 통해 이미지 분포를 학습 할 수 있다.

[GAN 문헌](https://arxiv.org/abs/1406.2661)

\\[ 
\min_{G} \max_{D} V(D,G) = E_{x \sim p_{data}(x)}[\log{D(x)}] + E_{z \sim p_{z}(z)}[\log{1-D(G(z))}]
\\]

위에서 \\(G\\)는 목적함수를 최대한 낮추고자 노력하고, \\(D\\)는 목적함수를 최대로 높이고자 노력하게 된다. 다시말해 우변의 첫번째 항은 원본 데이터에 대해서는 \\(D(x)\\)가 1을 뱉어낼 수 있게 하고, 두번째 항은 가짜 이미지에 대해서 0을 뱉어낼 수 있도록 학습하겠다는 뜻이다.

<img src="{{page.img_pth}}GAN_structure.png">

GAN은 위와 같이 학습을 진행하고, Discriminator를 통해 나온 값으로 Fake(0)와 Real(1)을 판별한다. 이 결과를 통해 Loss 값을 구하게 되고, 각 모델은 다음과 같이 업데이트 될 수 있다.

Generator는 목적함수를 낮춰야 하기 때문에 -ve 방향으로 업데이트:

\\[
\theta_G \leftarrow \theta_G - \eta \cdot \nabla_{\theta_G} \left( \frac{1}{m} \sum_{i=1}^{m} \log(D(G(z_i))) \right)
\\]

Discriminator는 Fake(0), Real(1)이 되는 방향으로 gradient를 타고 올라갈 수 있게 업데이트:

\\[
\theta_D \leftarrow \theta_D + \eta \cdot \nabla_{\theta_D} \left( \frac{1}{m} \sum_{i=1}^{m} \left[ \log(D(x_i)) + \log(1 - D(G(z_i))) \right] \right)
\\]

하게 된다.

동일한 목적함수 식에 대해서 \\(D\\)와 \\(G\\)는 서로 다른 목적을 가지기 때문에, **min-max**게임 이론에 기반하는 optimization문제로 볼 수 있다. 이런식으로 동일한 식으로 \\(G\\)는 minimize 하고 \\(D\\)는 maximize하는 방향으로 학습하면, 생성자는 "그럴싸한"이미지를 생성해 낼 수 있는 모델이 될 수 있다는게 문헌에서 주장하는 이론이다.

## GAN의 수렴 과정
위에서 언급 되었던 GAN 공식의 목표는 다음과 같다.
1. 생성자의 분포가 원본 학습 데이터의 분포를 잘 따를 수 있도록 만든다. (수렴)

\\[ P_{g} \rightarrow P_{data}\\]

2. 학습이 다 이루어 진 뒤, 가짜와 진짜이미지를 구분할 수 없기 때문에 50%라는 값을 내보낸다.

\\[ D(G(z)) \rightarrow 1/2\\]

<img src="{{page.img_pth}}GAN_schematic.png">

이 과정을 시간에 따라 그림으로 나타내면 위 그림과 같이 표현 할 수 있다. 생성자(초록색)은 Z 공간의 데이터를 X공간으로 매핑하는 것으로 표현할 수 있다. 처음엔 왼쪽의 첫번째 그림처럼 생성자의 분포가 원본 데이터의 분포를 잘 학습하지 못했기 때문에 판별자(파란색) 또한 이를 잘 구별하는 것을 볼 수 있다. 학습이 이루어짐에 따라서 학습한 분포가 원본 데이터의 분포를 적절히 따라갈 수 있기 때문에, 학습이 온전히 이루어 졌을 때 생성 모델의 분포가 원본 데이터(검정색 점)의 분포를 잘 학습하는 걸 볼 수 있고, 판별 모델은 1/2 로 수렴하는 것을 볼 수 있다.

그렇다면 학습을 진행할 때, 어떻게 생성자의 분포가 원본 학습 데이터의 분포에 수렴 할 수 있을까? 논문에서는 이를 가장 중요하게 여기는 증명 포인트이고 아래서 설명할 예정이다.

생성 모델이 원본 데이터의 분포를 잘 학습 한 후, 검은색 점에 해당하지 않은 데이터를 생성 모델 분포에서 꺼내게 된다면, 새로운 이미지(new data instance)가 되는 것이다. 또한 확률이 높은 구간(중심점)에서 약간의 noise를 섞어 데이터를 샘플링 하게 된다면, 원본 데이터는 아니지만 원본과 비슷한 이미지(데이터)를 생성 할 수 있게 되는 것이다.

## 증명
해당 증명은 \\(P_{g} \rightarrow P_{data}\\)로 수렴 하는지에 대해서 증명하는 과정이다.
### Global Optimality(1)
내 상황에 대해서 생성자와 판별자가 어떤 Global Optima를 가지는지에 대해서 설명하는 증명이다.

\\[proposition:\ D^*_{G(x)} = \frac{p\_{data}(x)}{p\_{data}(x) + p\_{g}(x)} \\]

**For fixed G,**

$$\begin{align}
V(G, D) &= E_{x \sim p_{data}(x)}[\log{D(x)}] + E_{z \sim p_{z}(z)}[\log{(1-D(G(z)))}] \\
&=\int_{x} p_{data}(x)(\log{D(x)}) dx + \int_{z}p_{z}(z)\log({1-D(G(z))}) dz \\
&=\int_{x} p_{data}(x)(\log{D(x)}) + p_{g}(x)\log({1-D(x)}) dx
\end{align}$$

첫번째 줄의 목적 함수를 아래와 같은 기댓값 공식을 이용하면 두번째 줄과 같이 유도 할 수 있다.

\\[ E[X] = \int^{\infty}_{-\infty}xf(x) dx\\]

두번째 줄 우변의 두번째 항은 z 도메인에서 샘플링 된 noise 벡터를 G에 넣어서 데이터 x를 만들어 낼 수 있기 때문에, 이러한 과정은 z 도메인에서 x로 매핑되는 것으로 볼 수 있다. 따라서 \\(G(z)\\)를 x로 치환하여 표현하게 된다면, 세번째 줄의 식과 같이 하나의 적분 식으로 나타낼 수 있다.

세번째 식을 간단하게 표현한다면, 다음과 같은 결론을 내릴 수 있다.

\\[ function\ y \rightarrow a\log(y) + b\log(1-y)\ achieves\ its\ maximum\ in\ [0, 1]\ at\ \frac{a}{a+b}\\]

y로 미분하여 극댓값을 찾으면 \\(\frac{a}{a+b}\\)를 가지는 것을 알 수 있다. GAN의 케이스는 a와 b는 상수이지만, 분포를 가지는 변수일 때에도 동일하게 계산이 가능하다.

정리해 보면, 위와 같은 적분 값이 명제(proposition)의 값을 가질 때 극댓값을 가지는 것을 알 수 있다. 

### Global Optimality(2)
\\[proposition:\ Global\ optimum\ point\ is\ \mathbf{p_g = p_{data}}\\]

해당 proposition은 생성자의 분포는 원본 데이터의 분포를 따라가게 된다 라는 것이다. 여기서 별도의 함수 \\(C(G)\\)를 정의하게 되는데, 이때 \\(C\\)는 이러한 \\(V\\)값을 최대로 만드는 \\(D\\)에대한 \\(V\\)함수이다.

정리하면, 특정한 \\(G\\)함수에 대해서 global optima를 가지는 \\(D\\)함수에 대한 \\(V\\)함수 라는 것이다.

$$\begin{align}
C(G) &= \max_{D}V(G,D) = E_{x \sim p_{data}(x)}[\log{D^*(x)}] + E_{z \sim p_{z}(z)}[\log{(1-D^*(G(z)))}] \\
&= E_{x \sim p_{data}(x)}\left[\log{\frac{p_{data}(x)}{p_{data}(x) + p_{g}(x)}}\right] + E_{x \sim p_{g}(x)}\left[\log{(\frac{p_{g}(x)}{p_{data}(x) + p_{g}(x)})}\right] \\
&= E_{x \sim p_{data}(x)}\left[\log{\frac{2*p_{data}(x)}{p_{data}(x) + p_{g}(x)}}\right] + E_{x \sim p_{g}(x)}\left[\log{(\frac{2*p_{g}(x)}{p_{data}(x) + p_{g}(x)})}\right] - \log(4) \\
&= KL\left(p_{data}||\frac{p_{data}(x)+p_g(x)}{2}\right) + KL\left(p_{g}||\frac{p_{data}(x)+p_g(x)}{2}\right) - \log(4) \\
&= 2 * JSD(p_{data}||p_g) - \log(4)
\end{align}$$

첫번째 줄에서, V를 최대로 가져갈 수 있는 \\(D^*(x)\\)는 이전에 증명한 값을 대입하면 두번째 줄과 같이 전개 할 수 있다.

증명의 편의를 위해 \\(\log\\)항 안의 값에 2를 곱해주고, 마지막에 \\(\log(4)\\)를 빼주면 세번째 줄의 결과를 얻을 수 있다.

세번째 줄에서 \\(p_g = p_{data}\\)라면 맨 마지막의 \\(\log\\)항을 제외한 나머지가 0이 되게 된다. 이는 `KL-Divergence`로 치환될 수 있고, 네번째 줄의 식과 같다.

[`KL-Divergence`](#kl-divergence)는 distance metric이 아니기 때문에, 두 분포를 비교할 수 있는 `JSD`로 치환하여 표현하게 되면 마지막 줄의 식과 같이 표현 할 수 있다. `JSD`는 distance metric이기 때문에, 두 분포의 최소 거리값은 0이게 된다. 다른 말로, \\(\mathbf{p_g = p_{data}}\\)일 경우에 해당 값은 0이 되고, 해당 함수의 최솟값으로 \\(-\log(4)\\)라는 값을 얻을 수 있게 된다.

### KL-Divergence
정보이론에서 정보량을 다음과 같은 현상을 효과적으로 나타내기 위해 \\(\log\\)를 사용한다.
- 확률이 높을수록: 당연하게 일어날 사건
- 확률이 낮을수록: 자주 일어나지 않는 사건

어떠한 확률의 `불확실성`에 대한 척도는 `Entropy`를 이용하여 정량적으로 계산 할 수 있다.

\\[H(P) = -\sum\limits_{i=1}P(i)\log(P(i))\\]

하지만 현재 가지고 있는 데이터(정답 데이터)를 \\(P(i)\\)라고 할 때, 이 데이터를 근사 할 수 있는 분포(모델을 통해 나온 데이터)를 \\(Q(i)\\)를 이용하여 `Entropy`를 구할 수 있을까? `Entropy`는 `정보량의 기댓값`이기 때문에 정보량은 \\(Q(i)\\), 사용되는 확률분포는 \\(P(i)\\)라고 한다면,

\\[H(P,Q) = \sum\limits_{i=1}P(i)\log\left(\frac{1}{Q(i)}\right) = -\sum\limits_{i=1}P(i)\log(Q(i))\\]

가 된다. 이를 우리는 `Cross-Entropy`로 정의하고, 실제 데이터는 \\(P(i)\\)분포로부터 생성되지만 \\(Q(i)\\)분포를 사용한 정보량의 기댓값을 의미한다.

`Cross-Entropy`는 `Entropy`보다 항상 크고, \\(P(i)=Q(i)\\) 일때만 같으므로, 두 항의 차이를 분포 사이의 거리"처럼" 사용 할 수 있다.

$$\begin{align}
KL(P||Q) &= H(P, Q) - H(P) \\
&= \sum\limits_i P(i)\log\frac{1}{Q(i)}+P(i)\log P(i) \\
&= \sum\limits_i P(i)\log \frac{P(i)}{Q(i)}
\end{align}$$

이를 `KL-Divergence` (Kullback–Leibler divergence)라고 하며, 정보 이론적인 관점에서 봤을 때 소스 분포인 \\(P(i)\\) 대신 다른 분포, \\(Q(i)\\), 를 사용하여 인코딩 할 때 얼마만큼의 정보가 낭비 되었나를 정량적으로 나타낼 수 있는지 표현 할 수 있는 식이라고 볼 수 있다.

다른 말로 \\(P(i)\\)와 \\(Q(i)\\)의 cross-entropy에서 \\(P(i)\\)의 entropy를 뺀 값, 즉 두 분포의 정보량 차이를 나타낸다고 볼 수 있다.

KL은 다음과 같은 특징이 있다.
\\[ KL(p||q) = 0 iff p=q \\]
\\[ KL(p||q) \geq 0 \\]
\\[ KL(p||q) \neq KL(q||p) \\]

KL의 세번째 특성 때문에 거리의 개념으로 쓰일 수가 없다. 하지만 두 분포가 다를수록 이 값은 더욱 커지며, 두 분포가 일치 할 때는 0이 되기 때문에 비슷한 용도로 쓰이곤 한다.

두가지의 `KL-Divergence`를 구하고 평균을 내는 방법을 `JSD`, Jensen-Shannon divergence, 라고 한다. 많이 쓰이는 방법은 아니지만 전의 경우와 같은 상황에 종종 쓰인다.

\\[JSD(P||Q) = \frac{1}{2}KL(Q||M) + \frac{1}{2}KL(P||M) \\]
\\[where,\ M = \frac{1}{2}(P+Q)\\]

DCGAN의 구현은 [다음](../implement-DCGAN)을 참고!