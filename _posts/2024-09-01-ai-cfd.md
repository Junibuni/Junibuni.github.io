---

title: Shallow Water Equation AI 모델 구현 - 스마트 시티 침수 예측 
date: 2024-09-01 12:43:00 +0800 
categories: [AI, Fluid Dynamics] 
tags: [shallow water equation, ai model, cfd, computer vision, image processing, deep learning, neural networks, python, pytorch, fluid simulation, machine learning, lstm, autoencoder, sph, urban flooding] 
use_math: true
---
# 스마트 시티 침수 예측: Shallow Water Equation과 AI 모델을 활용한 해결 방법

## 서론
물리 기반 시뮬레이션은 수치 해석 기법을 통해 자연 현상이나 물리적 시스템을 정밀하게 예측하는 데 중요한 역할을 한다. 특히, 스마트 시티와 같은 도시 환경에서 침수 문제는 기후 변화로 인한 집중 호우와 같은 극단적인 기상 현상에서 발생할 수 있으며, 실시간으로 대응해야 하는 중요한 문제이다. 기존의 수치 해석 기법은 높은 정확도를 제공하지만, 복잡한 계산으로 인해 실시간 예측에는 한계가 있다. 본 프로젝트에서는 이러한 문제를 해결하기 위해 AI 기술을 도입하여, 빠르고 정확한 침수 예측을 목표로 하고 있다.

스마트 시티는 다양한 센서와 데이터 기반의 인프라를 통해 도시 관리와 예측을 최적화하는 시스템을 의미한다. 그러나, 지형의 특성이나 인프라의 복잡성으로 인해 집중 호우 시 침수나 역류 현상이 발생할 수 있다. 특히, 맨홀에서 발생하는 역류는 도시의 하수 시스템을 마비시키고, 침수 범람을 가속화하여 도로, 지하철, 건물에 심각한 피해를 줄 수 있다. 이러한 상황에서는 빠르고 정확한 침수 예측이 필수적이며, 기존 물리 기반 해석기법은 한계가 명확히 존재한다.

[ANUGA](https://anuga.readthedocs.io/en/latest/)와 같은 수치 해석기는 천수 방정식(Shallow Water Equation)을 기반으로 스마트 시티 환경에서의 침수 예측을 수행할 수 있다. 천수 방정식은 물의 깊이 및 x, y 방향의 모멘텀을 계산하여 물의 흐름을 예측하는 방정식으로, 도시의 수리학적 문제를 해결하는 데 널리 사용되고 있다. 그러나, ANUGA와 같은 수치 해석기를 사용한 시뮬레이션은 한 케이스당 약 4시간의 계산 시간이 소요되며, 이는 실시간 대응에는 부적합한 문제를 가지고 있다.

따라서 본 프로젝트에서는 물리 기반 해석의 장점을 유지하면서도, 계산 시간을 크게 단축할 수 있는 AI 기반 예측 모델을 개발하고자 했다. 특히, 침수 범람 시 주요 변수인 맨홀 역류량과 같은 추가 변수를 고려하여 예측 정확도를 높이는 데 중점을 두었다. AI 모델은 Autoencoder와 LSTM을 결합하여 잠재 벡터를 통해 시계열 데이터로 침수 현상을 예측하도록 설계되었으며, 이를 통해 실시간 예측이 가능한 모델을 구현하고자 했다.

## 프로젝트 목표 및 개요

<img src="{{page.img_pth}}smartcity.png">

이 프로젝트의 목표는 AutoEncoder를 활용해 스마트시티의 침수 해석을 경량화하고, 실시간 예측이 가능한 해석 솔버를 개발하는 것이다. 특히 스마트시티 내 J01, J02, J03, J03-06, J06, J08-09 맨홀의 역류 상황을 예측할 수 있는 모델을 구축하였으며, 다양한 물리적 변수를 학습하여 효율적으로 압축된 **잠재 벡터(latent vector)**를 생성하는 AutoEncoder 모델을 구현하고자 했다.

이를 통해, 3D 3채널 이미지(물의 깊이, x와 y 방향 모멘텀)를 입력받아, 물의 수위를 2D 이미지 형태로 예측할 수 있도록 설계했다.

<img src="{{page.img_pth}}smartcity_AE.gif">

## 모델 구현 방법

이번 프로젝트의 핵심은 AI 모델을 통해 스마트 시티 환경에서 침수 예측의 속도와 효율성을 극대화하는 것이다. 이를 위해 **Autoencoder**와 **LSTM(Long Short-Term Memory)** 모델을 결합하여 물리 기반 시뮬레이션의 복잡한 계산을 대체할 수 있는 예측 모델을 구현했다. 이 과정에서는 **BigBlock-SmallBlock 구조**를 도입한 Autoencoder와 시계열 데이터를 다루는 LSTM을 활용하여, 침수 현상 예측에서 중요한 물리적 특징을 효과적으로 추출하고, 이를 바탕으로 시뮬레이션을 가속화하는 데 중점을 두었다.

### 1. Autoencoder 설계

**Autoencoder**는 입력 데이터를 저차원의 잠재 벡터 (latent vector)로 압축하고, 다시 이를 원래 차원의 데이터로 복원하는 비지도 학습 모델이다. 이 모델은 복잡한 시뮬레이션 데이터를 효율적으로 압축할 수 있는 특성을 가지고 있어, **Shallow Water Equation**을 기반으로 한 물리적 데이터를 학습하는 데 적합하다고 판단했다. 

특히, 이번 프로젝트에서는 **BigBlock-SmallBlock** 아키텍처를 도입하여 Autoencoder를 설계했다. 이 구조는 다중 스케일로 데이터를 처리할 수 있는 장점을 가지며, 깊이 있는 특성 추출이 가능하기 때문이다.

- **SmallBlock**: 각 SmallBlock은 3x3 커널 크기를 가진 합성곱(convolution) 레이어와 **LeakyReLU** 활성화 함수로 구성되어 있다. SmallBlock은 각 레이어에서 데이터를 점진적으로 처리하며, 주요 특징을 추출 할 수 있다.
- **BigBlock**: 여러 개의 SmallBlock이 모여 **BigBlock**을 형성한다. BigBlock은 입력 데이터를 여러 단계로 처리하며, 각 SmallBlock에서 추출된 특징을 누적하여 최종적으로 고차원 데이터를 압축한다. BigBlock 내부에서는 입력 데이터를 매 단계에서 스킵 연결(skip connection)하여, 원래 입력 데이터와 처리된 데이터를 함께 결합하여 더욱 풍부한 정보를 학습할 수 있도록 했다.

Autoencoder의 **Encoder**는 입력 이미지(침수 현상)를 저차원의 잠재 벡터로 변환하는 역할을 한다. 이때 입력 이미지에는 물의 깊이와 x, y 방향의 모멘텀이 포함되어 있으며, 이 정보는 각각의 채널로 나뉘어 3채널 이미지 형태로 입력되게 된다. 이후, 여러 개의 BigBlock을 통해 특징이 추출되고, 최종적으로 압축된 잠재 벡터가 생성된다.

**Decoder**는 이 잠재 벡터를 다시 원래 차원의 이미지로 복원하는 역할을 한다. Decoder는 Encoder와 대칭적인 구조를 가지며, 잠재 벡터를 입력받아 다시 원래 이미지로 복원한다. 이를 통해 침수 예측 시 필요한 물리적 정보를 담은 2D 이미지를 다시 생성할 수 있다.

이때 Loss 함수는 유체의 총량을 비교할 수 있는 depth 정보의 L2 loss, 수심의 gradient 정보를 학습시킬 수 있는 sobel gradient loss, 그리고 각 맨홀의 역류량을 비교할 수 있는 L2 loss 를 사용하여 학습을 진행했다.

#### 결과
Learning rate 를 2e-4, 각각의 loss ratio를 1, 1, 1 로 세팅 후 학습을 진행 했다.
<img src="{{page.img_pth}}smartcity_firstloss.png">

결과를 보면 loss 의 진동이 심하고, 1500step 이후에 발산하는 것을 확인할 수 있었다. Encoded 된 latent vector 는 -2~2 범위의 값을 가지게 되는데, 맨홀의 역류 데이터는 0~10 사이의 값을 가지기 때문에 normalize 시켜 비슷한 범위로 맞추어 해석을 진행했다.

<img src="{{page.img_pth}}smartcity_secondloss.png">
 
또한 각 loss마다의 스케일의 차이가 커서 학습이 고루 되지 않다고 판단되어 비율을 조절해 가며 학습을 진행했다. Loss 값들을 비슷한 단위로 학습이 되도록 scaling 후 학습했을 때 loss 자체의 값은 줄어들었지만, 여전히 진동이 심한 것을 볼 수 있다. 

모든 시뮬레이션의 초기 step은 모두 비슷한 값으로부터 시작되기 때문에 데이터마다의 상관관계가 커 학습이 제대로 진행되지 않을 수 도있다고 판단 되었다. 각 제이터셋마다 겹치거나 상관관계가 많은 피쳐들을 제거하고 학습을 진행 했다.

<img src="{{page.img_pth}}smartcity_thirdloss.png">

진동이 소폭 감소했으나, 여전히 진동은 존재하는 것을 확인할 수 있었다. 이상치에 민감하게 반응하는 L2 loss 외에 모든 지점에서 미분가능하며 이상치에 민감하지 않은 huber loss로 변경해 주었다. 또한, 학습이 진행함에 따라 learning rate가 크다고 판단하여 learning rate scheduler를 사용하여 조절해 주었다.

<img src="{{page.img_pth}}smartcity_fourthloss.png">

학습이 잘 됨을 확인하여 500epoch 이상 학습을 진행했다.

### 2. LSTM 기반 시계열 예측 모델

Autoencoder에서 생성된 잠재 벡터는 하나의 시간 스텝에서 도메인의 상태를 나타내는 정보이다. 하지만 침수 예측에서는 시간이 흐름에 따라 상태가 변하는 시계열 데이터를 처리해야 하므로, **LSTM(Long Short-Term Memory)** 모델을 도입하여 이를 해결했다.


- **Manifold Navigation**: LSTM 모델은 현재 시점의 잠재 벡터와 추가 변수(예: 맨홀 역류량)를 입력으로 받아, 다음 시점의 잠재 벡터와의 차이를 예측한다. 이때, LSTM의 입력으로는 현재 상태의 잠재 벡터와 각 시점에서의 **맨홀 역류량** 데이터가 결합된다. 이러한 방식은 물리적 현상을 더 정확하게 반영할 수 있으며, 단순히 이전 상태만을 고려하는 것이 아니라 추가 변수까지 통합하여 예측 정확도를 높일 수 있다.
  
  예를 들어, **현재 시점의 잠재 벡터**와 **맨홀 역류량**이 주어졌을 때, LSTM은 이를 학습하여 **다음 시점에서의 잠재 벡터 변화**를 예측하게 된다 (dx). 이를 통해 시계열 데이터의 흐름을 파악하고, 시간의 흐름에 따라 물리적 상태가 어떻게 변화하는지를 예측한다.

<img src="{{page.img_pth}}smartcity_latentvec.png">

위 그래프는 latent vector의 각 변수들을 나타낸 그래프이다. 각각의 element 들이 smooth하고, 맨홀의 역류량에 따른 변화가 명확하다. 세 그래프 모두 비슷한 케이스 이지만 맨홀의 역류량을 조절했을 때에는 빨간 그래프와 같이 변화가 명확한 것을 볼 수 있다.


### 3. 전체 시뮬레이션 흐름

최종적으로, Autoencoder와 LSTM을 결합한 전체 시뮬레이션 예측 과정은 다음과 같다:

1. **초기 상태 입력**: 시뮬레이션이 시작될 때, 2D 이미지 형태의 물의 깊이 및 모멘텀(x, y 방향)이 Autoencoder의 Encoder에 입력된다. 이를 통해 저차원 잠재 벡터가 생성된다.
  
2. **LSTM을 통한 잠재 벡터 예측**: 생성된 잠재 벡터는 LSTM 모델을 거치며, 시간의 흐름에 따라 각 시점에서 다음 상태의 잠재 벡터가 예측된다. 이때, **맨홀 역류량**과 같은 추가 변수도 함께 입력되어 예측의 정확도를 높인다.

3. **Decoder를 통한 이미지 복원**: 예측된 잠재 벡터는 다시 Decoder를 통해 원래 차원의 이미지로 복원된다. 이를 통해 다음 시점에서의 침수 상태(물의 깊이와 x, y 모멘텀)를 예측할 수 있다.

4. **전체 시뮬레이션 반복**: 이 과정을 반복하여 전체 시뮬레이션 과정을 예측하며, 시뮬레이션 결과는 영상 형태로 출력될 수 있다. 각 시점에서의 이미지 결과가 모여 **전체 시뮬레이션 영상**이 생성되게 된다.

<img src="{{page.img_pth}}smartcity_result.gif">

### 4. 모델 최적화 및 문제 해결

모델 구현 과정에서는 여러 문제점들이 발생하였으나, 이를 해결하기 위해 다양한 방법을 적용했다.
  
#### Multi-Step Prediction

Multi-Step Prediction은 이전 시점의 예측 결과를 사용해 다음 시점의 상태를 순차적으로 예측하는 방식이다. 하지만 초기 LSTM 모델에서는 **Single-Step 데이터**만으로 다음 시점의 상태를 예측했을 때 오차가 누적되는 문제가 발생했다. 시간이 지남에 따라 예측 정확도가 급격히 저하되었고, 안정적인 Multi-Step Prediction을 수행하기 어려웠다. 특히, **Overflow Indicator(맨홀 역류량)** 같은 추가 변수를 결합할 때 시계열 데이터와의 상관관계를 제대로 반영하지 못했다.


해결 방법

이 문제를 해결하기 위해 **Cross-Time-Step Learning** 방식을 도입해 여러 시점의 데이터를 동시에 학습하는 구조로 개선했다. 단일 시점 예측 대신 **Time Window**를 설정하고, 과거 여러 시점의 데이터를 입력으로 받아 다음 여러 시점의 상태를 예측하도록 만들었다.


1. **Time Window 설정**  
   LSTM 모델의 입력으로 **N개의 연속된 시점 데이터**를 사용해 다음 시점들의 상태를 예측한다.  
   - 예를 들어, \\([t-3, t-2, t-1, t]\\) 시점의 Latent Vector를 입력받아 \\([t+1, t+2, t+3]\\) 시점의 Latent Vector를 예측한다.  
   - 이 방식은 과거 데이터의 흐름을 더 잘 반영할 수 있도록 하고, **더 정확한 다단계 예측**을 수행하게 만든다.

2. **Feature Processing Layer 도입**  
   Overflow Indicator와 같은 추가 변수는 단순 결합 대신 **Feature Processing Layer**를 통해 처리하여 LSTM에 입력했다.  
   - 각 시점의 Latent Vector와 추가 변수를 결합하여 \\([\text{Latent Vector}, \text{Overflow Indicator}]\\) 형태로 입력한다.  
   - 이 방식은 시계열 데이터와 추가 변수의 관계를 명확하게 학습하게 해 **모델 성능**을 높였다.

3. **Teacher Forcing 사용**  
   학습 과정에서 **Teacher Forcing** 기법을 사용해 모델이 초기 학습 단계에서 오차가 누적되지 않도록 했다.  
   - 학습 초반에는 예측된 값을 입력으로 사용하지 않고, **실제 정답 데이터**를 다음 시점의 입력으로 사용했다.  
   - 이후 모델이 충분히 학습된 후에는 Teacher Forcing을 점진적으로 줄이고, 예측된 값을 입력으로 사용하는 방식으로 전환했다.


개선 결과

1. **예측 안정성 향상**  
   여러 시점의 데이터를 동시에 학습하는 구조를 통해 Multi-Step Prediction에서 발생하던 오차 누적 문제를 해결했다. 이를 통해 **일관된 예측 성능**을 확보했다.

2. **추가 변수 활용 극대화**  
   Feature Processing Layer로 Overflow Indicator와 같은 변수와 Latent Vector가 효과적으로 결합되면서 예측 정확도를 높였다.

3. **학습 속도와 성능 개선**  
   Teacher Forcing 기법을 사용해 모델 학습 속도가 빨라졌고, 학습 이후에도 Multi-Step Prediction에서 **높은 일반화 성능**을 유지했다.

#### AutoEncoder 안정성
 
Autoencoder 모델은 물리 기반 시뮬레이션에서 중요한 물리적 특징을 학습해야 하며, 이를 통해 **Shallow Water Equation(SWE)**에 포함된 물의 흐름과 모멘텀을 정확하게 반영할 수 있어야 한다. 특히 입력 데이터가 **3채널 이미지(물의 깊이, x 방향 모멘텀, y 방향 모멘텀)** 형태이기 때문에, 각 채널의 정보가 고르게 학습되고 결과에 반영되도록 모델을 신중하게 설계했다. 

해결 방법

1. Skip Connection을 활용한 정보 보존  
  - Autoencoder 구조의 **BigBlock-SmallBlock**에서, 입력 데이터의 중요한 특징이 학습 과정에서 손실되지 않도록 **Skip Connection**을 활용했다.  
    - Skip Connection은 Encoder에서 추출된 중간 결과를 Decoder에 직접 연결하여 원래 입력 데이터의 특성을 보존한다.
    - 특히, 물의 깊이와 모멘텀은 각각 시뮬레이션 결과에 큰 영향을 미치기 때문에, 이런 중요한 물리적 정보를 Decoder에서 복원할 수 있도록 구성했다.

2. Reconstruction Loss 조정  
  - Autoencoder 학습에서 사용된 **Reconstruction Loss**는 입력 이미지와 복원된 이미지 간의 차이를 최소화하는 데 초점을 맞췄다. 
    - 이때 각 채널의 중요도를 고려해 **채널별 가중치(weighted loss)**를 적용했다. 예를 들어, 물의 깊이 채널의 정보가 더 중요한 경우 해당 채널의 오차에 더 큰 가중치를 부여했다. 
    - 이 방식을 통해 모델이 학습 과정에서 모든 채널을 고르게 학습하면서도, 중요한 채널의 정보가 더욱 정확하게 반영되도록 유도했다.

3. Latent Vector의 정보 보존 최적화  
  - Encoder는 입력 데이터를 압축하여 **Latent Vector(잠재 벡터)**로 변환한다. 이 과정에서 물리적 특성을 충분히 보존하기 위해 **Conv2D 필터 수와 차원 축소 단계**를 조정했다. 또한, Latent Vector의 길이를 변경해 가면서 (8, 16, 32) 테스트도 해보았다.
    - 채널 수를 **log₂(d_max) - 2** 단계로 축소하면서도 물리적 정보 손실을 최소화할 수 있도록 설계했다. 
    - Latent Vector에 포함된 정보가 충분히 보존되어야, 이후 **LSTM 모델**이 이를 바탕으로 정확한 시계열 예측을 수행할 수 있다.

4. Batch Normalization과 Dropout 적용  
  - 학습 과정에서 모델의 일반화 성능을 높이고, 특정 채널에 과적합되지 않도록 **Batch Normalization**과 **Dropout**을 적용했다. 
    - Batch Normalization은 각 채널의 데이터 분포를 정규화해 학습 속도를 높이고, **Gradient Vanishing** 문제를 방지했다.
    - Dropout은 학습 과정에서 일부 뉴런을 무작위로 비활성화해 과적합(overfitting)을 방지하며, 모델의 **일반화 성능**을 높이는 역할을 했다.

개선 결과

이와 같은 학습 과정을 통해 Autoencoder 모델은 물리적 시뮬레이션에서 필요한 중요한 특징들을 정확하게 학습할 수 있었다. 각 채널의 정보가 균등하게 반영되었고, Reconstruction Loss를 최적화해 시뮬레이션 결과와의 일관성을 유지했다. Latent Vector 역시 물의 깊이와 모멘텀의 특성을 충분히 보존하도록 설계되어, 이후 **LSTM 기반 시계열 예측 모델**에서 정확한 예측을 수행할 수 있게 되었다.